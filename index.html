<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="font-variant: small-caps;">FlowRetrieval</span>: Flow-Guided Data Retrieval for Few-Shot Imitation Learning</h1>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Keunhong Park</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Jonathan T. Barron</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span>
          </div> -->

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning in robotics requires extensive amount of demonstrations while zero-shot performance of such pretrained policies often struggle.
            It is critical to develop few-shot adaptation strategies that rely on a small amount of demonstrations for the target task.
            Recent research has shown that augmenting training data with past experiences can provide abundant signals when learning from small data.
            However, existing data retrieval methods fall under two extremes: they either rely on the existence of <em>exact same</em> behaviors with visually similar objects in the prior data, which is impractical to assume; or they retrieve based on semantic similarity of high-level language descriptions of the task, which might not be that informative about the shared behaviors or motions across tasks.
            In this work, we investigate how we can leverage the vast amount of cross-task data that share similar <em>motion</em> with the target task to improve few-shot imitation learning.
            Our key insight is that motion-similar data carry rich information about the effects of actions and object interactions that can be leveraged during few-shot adaptation.
            We propose <span style="font-variant: small-caps;">FlowRetrieval</span>, an approach that leverages optical flow representations for both extracting similar motions to target tasks from prior data, and for guiding learning of a policy that can maximally benefit from such data.
            Our results show <span style="font-variant: small-caps;">FlowRetrieval</span> significantly outperforms prior methods across simulated and real-world domains, with over 4X performance of vanilla imitation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<!-- Method Overview. -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
          <div class="content">
            <h2 class="title is-3">Method Overview</h2>
            <p>
              We learn a motion-centric latent space for retrieving motions similar to target data from prior data and further guide policy learning with optical flow.
            </p>
            <img src="./static/images/1_overview.png"
                  class="method-overview-image"
                  alt="Method Overview"/>
            <ul>
              <li><b>Motion-Centric Pretraining</b>: <span style="font-variant: small-caps;">FlowRetrieval</span> acquires a motion-centric latent space by computing optical flow between the current frame and a future frame of the robot's RGB visual observations, and employing a variational autoencoder (VAE) to embed the optical flow data.</li>
              <li><b>Data Retrieval with the Learned Motion-Centric Latent Space</b>: We select the nearest neighbors of target task in the latent space from previously collected data.</li>
              <li><b>Flow-Guided Learning</b>: During policy learning, <span style="font-variant: small-caps;">FlowRetrieval</span> leverages an auxiliary loss of predicting the optical flow as additional guidance for representation learning, encouraging the model to encode the image with enough details to reconstruct optical flow alongside predicting the action.</li>
            </ul>
          </div>
    </div>
  </div>
</section>
<!--/ Method Overview. -->

<!-- Experiments. -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Experiments</h2>

    <h3 class="title is-4">Tasks</h3>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h4 class="title is-6">Square Assembly</h4>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h4 class="title is-6">LIBERO-Can</h4>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h4 class="title is-6">Bridge-Pot</h4>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h4 class="title is-6">Bridge-Microwave</h4>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="content">
          <h4 class="title is-6 has-text-centered">Franka-Pen-in-Cup</h4>
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <br/>

    <h3 class="title is-4">Quantitative Results</h3>
    <p style="text-align:center;"><img src="./static/images/5_results_full.png"/></p>
    <br/>

    <h3 class="title is-4">Qualitative Analysis</h3>
    <p style="text-align:center;"><img src="./static/images/5_retrieval_viz.png"/></p>
    <br/>
    <p style="text-align:center;"><img src="./static/images/5_square_retrieval_bar.png"/></p>

  </div>
</section>
<!--/ Experiments. --> 

<!-- Rollouts -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Rollouts</h2>
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h4 class="title is-6">Square Assembly</h4>
              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/dollyzoom-stacked.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>

          <div class="column">
            <div class="content">
              <h4 class="title is-6">LIBERO-Can</h4>
              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/dollyzoom-stacked.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h4 class="title is-6">Bridge-Pot</h4>
              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/dollyzoom-stacked.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>

          <div class="column">
            <div class="content">
              <h4 class="title is-6">Bridge-Microwave</h4>
              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/dollyzoom-stacked.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column is-half">
            <div class="content">
              <h4 class="title is-6 has-text-centered">Franka-Pen-in-Cup</h4>
              <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 100%">
                <source src="./static/videos/dollyzoom-stacked.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>
    </div>
  </div>
</section>
<!--/ Rollouts. --> 

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>